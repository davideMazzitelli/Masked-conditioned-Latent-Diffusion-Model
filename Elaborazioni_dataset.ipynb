{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "22VznaGUNRS9",
        "r76crKkwfYWv",
        "S5tNQJJxGwPd",
        "pLI3XqCU7Skm",
        "8avLJ2N5vDmG",
        "Lgid7NhLGz30",
        "JGTKkOX6u65y"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpfSHDWqqht2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fca08f33-c1a6-43f1-9333-bd1f77c4cb0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conteggio macro categorie del dataset originale"
      ],
      "metadata": {
        "id": "22VznaGUNRS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "# Percorso della cartella delle annotazioni\n",
        "annotations_dir = '/content/drive/MyDrive/Colab Notebooks/TACO dataset/ds/ann'\n",
        "\n",
        "# Lista delle classi\n",
        "classes = [\n",
        "    'background', \"Plastic bag & wrapper\", \"Cup\", \"Plastic gloves\", \"Styrofoam piece\",\n",
        "    \"Aluminium foil\", \"Shoe\", \"Unlabeled litter\", \"Lid\", \"Rope & strings\",\n",
        "    \"Broken glass\", \"Paper bag\", \"Blister pack\", \"Carton\", \"Bottle cap\", \"Paper\",\n",
        "    \"Plastic container\", \"Pop tab\", \"Straw\", \"Bottle\", \"Plastic utensils\",\n",
        "    \"Other plastic\", \"Glass jar\", \"Battery\", \"Food waste\", \"Scrap metal\",\n",
        "    \"Can\", \"Cigarette\", \"Squeezable tube\"\n",
        "]\n",
        "\n",
        "# Dizionario per tenere traccia del conteggio delle classi\n",
        "class_counts = defaultdict(int)\n",
        "\n",
        "# Set per tracciare gli oggetti giÃ  conteggiati per ID\n",
        "counted_object_ids = set()\n",
        "\n",
        "# Itera su ogni file nella directory delle annotazioni\n",
        "for filename in os.listdir(annotations_dir):\n",
        "    if filename.endswith('.json'):  # Considera solo i file JSON\n",
        "        file_path = os.path.join(annotations_dir, filename)\n",
        "        with open(file_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "            # Itera sugli oggetti presenti nelle annotazioni\n",
        "            for obj in data.get(\"objects\", []):\n",
        "                # Trova il valore del supercategory dai tag dell'oggetto\n",
        "                supercategory = None\n",
        "                for tag in obj.get(\"tags\", []):\n",
        "                    if tag.get(\"name\") == \"supercategory\":\n",
        "                        supercategory = tag.get(\"value\")\n",
        "                        break\n",
        "\n",
        "                # Controlla se l'oggetto ha piÃ¹ di 2 punti (per i contorni)\n",
        "                points = obj.get(\"points\", {}).get(\"exterior\", [])\n",
        "                if len(points) > 2:\n",
        "                    # Se l'oggetto non Ã¨ giÃ  stato contato\n",
        "                    if supercategory in classes and obj['id'] not in counted_object_ids:\n",
        "                        # Incrementa il conteggio per la classe\n",
        "                        class_counts[supercategory] += 1\n",
        "                        # Aggiungi l'ID dell'oggetto al set per evitare il doppio conteggio\n",
        "                        counted_object_ids.add(obj['id'])\n",
        "\n",
        "# Stampa il conteggio totale per ogni classe\n",
        "print(\"Conteggio oggetti per classe:\")\n",
        "for cls in classes:\n",
        "    print(f\"{cls}: {class_counts[cls]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twqP_Io_NCFU",
        "outputId": "203cdd2b-218d-4244-ebfc-2c847f7b0f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conteggio oggetti per classe:\n",
            "background: 0\n",
            "Plastic bag & wrapper: 976\n",
            "Cup: 195\n",
            "Plastic gloves: 0\n",
            "Styrofoam piece: 124\n",
            "Aluminium foil: 62\n",
            "Shoe: 7\n",
            "Unlabeled litter: 551\n",
            "Lid: 94\n",
            "Rope & strings: 30\n",
            "Broken glass: 142\n",
            "Paper bag: 28\n",
            "Blister pack: 7\n",
            "Carton: 255\n",
            "Bottle cap: 290\n",
            "Paper: 151\n",
            "Plastic container: 72\n",
            "Pop tab: 99\n",
            "Straw: 183\n",
            "Bottle: 448\n",
            "Plastic utensils: 44\n",
            "Other plastic: 290\n",
            "Glass jar: 6\n",
            "Battery: 2\n",
            "Food waste: 8\n",
            "Scrap metal: 20\n",
            "Can: 275\n",
            "Cigarette: 669\n",
            "Squeezable tube: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download immagini e maschere"
      ],
      "metadata": {
        "id": "r76crKkwfYWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_taco_images_and_masks(annotations_path, target_class=None, max_images=None, image_output_dir=None, mask_output_dir=None, skip_existing=True):\n",
        "    \"\"\"\n",
        "    Scarica immagini da TACO e genera maschere semantiche basate sulle categorie secondo class_finals.\n",
        "    Gestisce correttamente l'orientamento EXIF per evitare rotazioni tra immagini e maschere.\n",
        "\n",
        "    NOVITÃ€: PuÃ² filtrare per una classe specifica e limitare il numero di immagini scaricate.\n",
        "\n",
        "    Args:\n",
        "        annotations_path (str): Path alle annotazioni json\n",
        "        target_class (int, optional): ID della classe da scaricare (es. 4 per carta/cartone). Se None, scarica tutte.\n",
        "        max_images (int, optional): Numero massimo di immagini da scaricare per la classe target. Se None, nessun limite.\n",
        "        image_output_dir (str, optional): Cartella per immagini. Default = stessa di annotations.\n",
        "        mask_output_dir (str, optional): Cartella per maschere. Default = image_output_dir/masks\n",
        "        skip_existing (bool): Se True, salta immagini e maschere giÃ  esistenti. Se False, rigenera tutto.\n",
        "\n",
        "    Returns:\n",
        "        int: Numero immagini scaricate\n",
        "    \"\"\"\n",
        "\n",
        "    import os\n",
        "    import json\n",
        "    import requests\n",
        "    import sys\n",
        "    import numpy as np\n",
        "    from PIL import Image, ImageDraw, ImageOps\n",
        "    from io import BytesIO\n",
        "    from collections import defaultdict\n",
        "\n",
        "    # Dizionario fornito dall'utente\n",
        "    class_finals = {\n",
        "        # PLASTICA E POLIMERI (1)\n",
        "    \"Other plastic bottle\": 1,\n",
        "    \"Clear plastic bottle\": 1,\n",
        "    \"Plastic bottle cap\": 1,\n",
        "    \"Spread tub\": 1,\n",
        "    \"Tupperware\": 1,\n",
        "    \"Disposable food container\": 1,\n",
        "    \"Other plastic container\": 1,\n",
        "    \"Plastic film\": 1,\n",
        "    \"Garbage bag\": 1,\n",
        "    \"Single-use carrier bag\": 1,\n",
        "    \"Polypropylene bag\": 1,\n",
        "    \"Plastified paper bag\": 1,\n",
        "    \"Carded blister pack\": 1,\n",
        "    \"Other plastic wrapper\": 1,\n",
        "    \"Crisp packet\": 1,\n",
        "    \"Disposable plastic cup\": 1,\n",
        "    \"Other plastic cup\": 1,\n",
        "    \"Plastic lid\": 1,\n",
        "    \"Plastic glooves\": 1,\n",
        "    \"Plastic utensils\": 1,\n",
        "    \"Plastic straw\": 1,\n",
        "    \"Other plastic\": 1,\n",
        "    \"Six pack rings\": 1,\n",
        "\n",
        "    # METALLI (2)\n",
        "    \"Food Can\": 2,\n",
        "    \"Aerosol\": 2,\n",
        "    \"Drink can\": 2,\n",
        "    \"Metal bottle cap\": 2,\n",
        "    \"Metal lid\": 2,\n",
        "    \"Pop tab\": 2,\n",
        "    \"Scrap metal\": 2,\n",
        "    \"Aluminium foil\": 2,\n",
        "    \"Aluminium blister pack\": 2,\n",
        "\n",
        "    # VETRO (3)\n",
        "    \"Glass bottle\": 3,\n",
        "    \"Glass jar\": 3,\n",
        "    \"Glass cup\": 3,\n",
        "    \"Broken glass\": 3,\n",
        "\n",
        "    # CARTA E CARTONE (4)\n",
        "    \"Other carton\": 4,\n",
        "    \"Egg carton\": 4,\n",
        "    \"Drink carton\": 4,\n",
        "    \"Corrugated carton\": 4,\n",
        "    \"Meal carton\": 4,\n",
        "    \"Pizza box\": 4,\n",
        "    \"Magazine paper\": 4,\n",
        "    \"Normal paper\": 4,\n",
        "    \"Wrapping paper\": 4,\n",
        "    \"Paper bag\": 4,\n",
        "    \"Paper cup\": 4,\n",
        "    \"Paper straw\": 4,\n",
        "    \"Tissues\": 4,\n",
        "    \"Toilet tube\": 4,\n",
        "\n",
        "    # polistirolo (5)\n",
        "    \"Foam cup\": 5,\n",
        "    \"Foam food container\": 5,\n",
        "    \"Styrofoam piece\": 5,\n",
        "\n",
        "    # SIGARETTE (6)\n",
        "    \"Food waste\": 6,\n",
        "    \"Battery\": 6,\n",
        "    \"Cigarette\": 6,\n",
        "\n",
        "    # DA RIMUOVERE (8)\n",
        "    \"Shoe\": 8,\n",
        "    \"Rope & strings\": 8,\n",
        "    \"Squeezable tube\": 8,\n",
        "\n",
        "    # NON CLASSIFICATI (7)\n",
        "    \"Unlabeled litter\": 7\n",
        "    }\n",
        "\n",
        "    def get_exif_rotation_angle(img):\n",
        "        \"\"\"Restituisce l'angolo di rotazione basato sui metadati EXIF\"\"\"\n",
        "        try:\n",
        "            exif = img._getexif()\n",
        "            if exif is not None:\n",
        "                orientation = exif.get(274)  # Tag EXIF per orientamento\n",
        "                if orientation == 3:\n",
        "                    return 180\n",
        "                elif orientation == 6:\n",
        "                    return 270\n",
        "                elif orientation == 8:\n",
        "                    return 90\n",
        "        except:\n",
        "            pass\n",
        "        return 0\n",
        "\n",
        "    def apply_rotation_to_polygon(polygon, angle, width, height):\n",
        "        \"\"\"Applica la rotazione ai punti del poligono\"\"\"\n",
        "        if angle == 0:\n",
        "            return polygon\n",
        "\n",
        "        points = []\n",
        "        for i in range(0, len(polygon), 2):\n",
        "            x, y = polygon[i], polygon[i+1]\n",
        "\n",
        "            if angle == 90:\n",
        "                new_x, new_y = height - y, x\n",
        "                new_width, new_height = height, width\n",
        "            elif angle == 180:\n",
        "                new_x, new_y = width - x, height - y\n",
        "                new_width, new_height = width, height\n",
        "            elif angle == 270:\n",
        "                new_x, new_y = y, width - x\n",
        "                new_width, new_height = height, width\n",
        "            else:\n",
        "                new_x, new_y = x, y\n",
        "                new_width, new_height = width, height\n",
        "\n",
        "            points.extend([new_x, new_y])\n",
        "\n",
        "        return points, new_width, new_height\n",
        "\n",
        "    def image_contains_target_class(image_id, annotations, category_id_to_name, target_class):\n",
        "        \"\"\"Verifica se un'immagine contiene la classe target\"\"\"\n",
        "        anns = image_id_to_anns[image_id]\n",
        "        for ann in anns:\n",
        "            category_id = ann['category_id']\n",
        "            category_name = category_id_to_name.get(category_id)\n",
        "            label_id = class_finals.get(category_name, 0)\n",
        "            if label_id == target_class:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    if image_output_dir is None:\n",
        "        image_output_dir = os.path.dirname(annotations_path)\n",
        "    if mask_output_dir is None:\n",
        "        mask_output_dir = os.path.join(image_output_dir, \"masks\")\n",
        "\n",
        "    os.makedirs(image_output_dir, exist_ok=True)\n",
        "    os.makedirs(mask_output_dir, exist_ok=True)\n",
        "\n",
        "    with open(annotations_path, 'r') as f:\n",
        "        annotations = json.load(f)\n",
        "\n",
        "    category_id_to_name = {c['id']: c['name'] for c in annotations['categories']}\n",
        "    image_id_to_anns = defaultdict(list)\n",
        "    for ann in annotations['annotations']:\n",
        "        image_id_to_anns[ann['image_id']].append(ann)\n",
        "\n",
        "    images_to_process = annotations['images']\n",
        "    if target_class is not None:\n",
        "        images_to_process = [img for img in annotations['images']\n",
        "                           if image_contains_target_class(img['id'], annotations, category_id_to_name, target_class)]\n",
        "        print(f\"Trovate {len(images_to_process)} immagini contenenti la classe {target_class}\")\n",
        "\n",
        "    if max_images is not None and len(images_to_process) > max_images:\n",
        "        images_to_process = images_to_process[:max_images]\n",
        "        print(f\"Limitate a {max_images} immagini\")\n",
        "\n",
        "    nr_images = len(images_to_process)\n",
        "    downloaded_count = 0\n",
        "    skipped_count = 0\n",
        "\n",
        "    print(f\"Processando {nr_images} immagini...\")\n",
        "\n",
        "    for i, image in enumerate(images_to_process):\n",
        "        file_name = image['file_name']\n",
        "        url_original = image['flickr_url']\n",
        "        width, height = image['width'], image['height']\n",
        "\n",
        "        subfolder = os.path.dirname(file_name)\n",
        "        base_name = os.path.basename(file_name)\n",
        "        new_file_name = f\"{subfolder}_{base_name}\" if subfolder else base_name\n",
        "\n",
        "        img_path = os.path.join(image_output_dir, new_file_name)\n",
        "        mask_path = os.path.join(mask_output_dir, new_file_name.replace('.jpg', '.png').replace('.JPG', '.png'))\n",
        "\n",
        "        if skip_existing and os.path.isfile(img_path) and os.path.isfile(mask_path):\n",
        "            skipped_count += 1\n",
        "            bar_size = 30\n",
        "            x = int(bar_size * i / nr_images)\n",
        "            sys.stdout.write(\"%s[%s%s] - %i/%i (skipped: %i)\\r\" % ('Processing: ', \"=\" * x, \".\" * (bar_size - x), i + 1, nr_images, skipped_count))\n",
        "            sys.stdout.flush()\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            if not os.path.isfile(img_path):\n",
        "                response = requests.get(url_original)\n",
        "                response.raise_for_status()\n",
        "\n",
        "                img_raw = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "                rotation_angle = get_exif_rotation_angle(img_raw)\n",
        "\n",
        "                img = ImageOps.exif_transpose(img_raw)\n",
        "                img.save(img_path)\n",
        "                downloaded_count += 1\n",
        "            else:\n",
        "                img_raw = Image.open(img_path).convert('RGB')\n",
        "                rotation_angle = get_exif_rotation_angle(img_raw)\n",
        "                img = ImageOps.exif_transpose(img_raw)\n",
        "\n",
        "            if not skip_existing or not os.path.isfile(mask_path):\n",
        "                if rotation_angle in [90, 270]:\n",
        "                    final_width, final_height = height, width\n",
        "                else:\n",
        "                    final_width, final_height = width, height\n",
        "\n",
        "                mask = np.zeros((final_height, final_width), dtype=np.uint8)\n",
        "                anns = image_id_to_anns[image['id']]\n",
        "\n",
        "                for ann in anns:\n",
        "                    category_id = ann['category_id']\n",
        "                    category_name = category_id_to_name.get(category_id)\n",
        "                    label_id = class_finals.get(category_name, 0)\n",
        "\n",
        "                    segmentation = ann.get('segmentation', [])\n",
        "                    for poly in segmentation:\n",
        "                        if rotation_angle != 0:\n",
        "                            rotated_poly, mask_width, mask_height = apply_rotation_to_polygon(\n",
        "                                poly, rotation_angle, width, height\n",
        "                            )\n",
        "                        else:\n",
        "                            rotated_poly = poly\n",
        "                            mask_width, mask_height = width, height\n",
        "\n",
        "                        mask_img = Image.new('L', (mask_width, mask_height), 0)\n",
        "                        ImageDraw.Draw(mask_img).polygon(rotated_poly, outline=label_id, fill=label_id)\n",
        "                        mask_array = np.array(mask_img)\n",
        "                        mask = np.maximum(mask, mask_array)\n",
        "\n",
        "                img_width, img_height = img.size\n",
        "                if mask.shape[1] != img_width or mask.shape[0] != img_height:\n",
        "                    mask_resized = Image.fromarray(mask).resize((img_width, img_height), Image.NEAREST)\n",
        "                else:\n",
        "                    mask_resized = Image.fromarray(mask)\n",
        "\n",
        "                mask_resized.save(mask_path)\n",
        "\n",
        "        except requests.exceptions.HTTPError as e:\n",
        "            if e.response.status_code == 403:\n",
        "                print(f\"\\nError 403: {file_name} - {url_original}\")\n",
        "            else:\n",
        "                print(f\"\\nErrore HTTP su {file_name}: {e}\")\n",
        "            continue\n",
        "        except Exception as e:\n",
        "            print(f\"\\nErrore nel processare {file_name}: {e}\")\n",
        "            continue\n",
        "\n",
        "        bar_size = 30\n",
        "        x = int(bar_size * i / nr_images)\n",
        "        sys.stdout.write(\"%s[%s%s] - %i/%i (skipped: %i)\\r\" % ('Processing: ', \"=\" * x, \".\" * (bar_size - x), i + 1, nr_images, skipped_count))\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    sys.stdout.write('Finished\\n')\n",
        "\n",
        "    if target_class is not None:\n",
        "        print(f'Scaricate {downloaded_count} nuove immagini della classe {target_class} (saltate {skipped_count}) e generate maschere in {mask_output_dir}')\n",
        "    else:\n",
        "        print(f'Scaricate {downloaded_count} nuove immagini (saltate {skipped_count}) e generate maschere in {mask_output_dir}')\n",
        "\n",
        "    return downloaded_count"
      ],
      "metadata": {
        "id": "zmginNr0arv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_taco_images_and_masks(annotations_path='/content/drive/MyDrive/TACO dataset/annotations.json',\n",
        "                               image_output_dir='/content/drive/MyDrive/TACO dataset/images_new_categories',\n",
        "                               mask_output_dir='/content/drive/MyDrive/TACO dataset/masks_new_categories')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "31f2CsmsJZeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_taco_images_and_masks(annotations_path='/content/drive/MyDrive/TACO dataset/annotations_unofficial.json',\n",
        "                               target_class=3,\n",
        "                               image_output_dir='/content/drive/MyDrive/TACO dataset/images_new_categories',\n",
        "                               mask_output_dir='/content/drive/MyDrive/TACO dataset/masks_new_categories')"
      ],
      "metadata": {
        "id": "KSoWRqTNz7QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rimozione immagini e maschere contenenti la classe 8 (da rimuovere)"
      ],
      "metadata": {
        "id": "Y0jBs_bPDHgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def remove_images_with_class_8(image_dir, mask_dir):\n",
        "    \"\"\"\n",
        "    Elimina le immagini e le maschere se la classe 8 Ã¨ presente nella maschera (classe da rimuovere).\n",
        "\n",
        "    Args:\n",
        "        image_dir (str): Path alla cartella contenente le immagini.\n",
        "        mask_dir (str): Path alla cartella contenente le maschere (grayscale PNG).\n",
        "    \"\"\"\n",
        "\n",
        "    removed_count = 0\n",
        "    total_files = len(os.listdir(mask_dir))\n",
        "\n",
        "    for i, mask_filename in enumerate(os.listdir(mask_dir)):\n",
        "        if not mask_filename.lower().endswith('.png'):\n",
        "            continue\n",
        "\n",
        "        mask_path = os.path.join(mask_dir, mask_filename)\n",
        "        image_path = os.path.join(image_dir, mask_filename.replace('.png', '.jpg'))\n",
        "\n",
        "        if not os.path.isfile(image_path):\n",
        "            image_path = image_path.replace('.jpg', '.JPG')\n",
        "            if not os.path.isfile(image_path):\n",
        "                print(f\"Immagine non trovata per {mask_filename}\")\n",
        "                continue\n",
        "\n",
        "        try:\n",
        "            mask = np.array(Image.open(mask_path))\n",
        "            if 8 in mask:\n",
        "                os.remove(mask_path)\n",
        "                os.remove(image_path)\n",
        "                removed_count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"Errore con {mask_filename}: {e}\")\n",
        "\n",
        "        bar_size = 30\n",
        "        x = int(bar_size * i / total_files)\n",
        "        print(\"%s[%s%s] - %i/%i\" % ('Elaborazione: ', \"=\" * x, \".\" * (bar_size - x), i+1, total_files), end=\"\\r\")\n",
        "\n",
        "    print(f\"\\nRimosse {removed_count} coppie immagine/maschera contenenti la classe 8.\")\n"
      ],
      "metadata": {
        "id": "RSHW1YT9ullQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_images_with_class_8(\"/content/drive/MyDrive/TACO dataset/images_new_categories\", \"/content/drive/MyDrive/TACO dataset/masks_new_categories\")"
      ],
      "metadata": {
        "id": "b8ujRNTcumvC",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Elaborazione annotazioni manuali"
      ],
      "metadata": {
        "id": "S5tNQJJxGwPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''fine_tune_dict = {\n",
        "    0: (0,0,0), # background\n",
        "    1: (102,255,102), #ferro e alluminio\n",
        "    2: (170, 240, 209), # Bottiglie plastica\n",
        "    3: (250,50,83), # Bottiglie vetro\n",
        "    4: (50,183,250), # Tappi e coperchi\n",
        "    5: (221,255,51), # Vetro rotto\n",
        "    6: (51,221,255), # Lattine\n",
        "    7: (89,134, 179), # cartone\n",
        "    8: (36,179,83), # Bicchieri\n",
        "    9: (255,0,204), # Plastica generica\n",
        "    10: (52,209,183), # Carta\n",
        "    11: (250,125,187), # Sacchetti e buste di plastica\n",
        "    12: (34,25,77), # Spazzatura generica\n",
        "    13: (138,138,138), # Cannucce\n",
        "    14: (255,96,55), # Polistirolo\n",
        "    15: (184,61,245) # Sigarette\n",
        "}'''\n",
        "\n",
        "fine_tune_dict={\n",
        "    0: (0,0,0),\n",
        "    1: (51,221,255),\n",
        "    2: (250,50,83),\n",
        "    3: (52,209,183),\n",
        "    4: (255,0,124),\n",
        "    100: (255,96,55),\n",
        "    5: (221,255,51),\n",
        "    6: (36,179,83),\n",
        "    7: (184,61,245)\n",
        "}"
      ],
      "metadata": {
        "id": "1MGnyXiRekyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "creazione maschere RGB -> grayscale"
      ],
      "metadata": {
        "id": "Bt33M1cSG-sP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def replace_colors_with_grayscale(image_folder, fine_tune_dict, output_folder):\n",
        "    \"\"\"\n",
        "    Sostituisce i colori in un set di immagini con i valori delle chiavi del dizionario in scala di grigi.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Creazione della mappa colori\n",
        "    color_map = {tuple(color): key for key, color in fine_tune_dict.items()}\n",
        "\n",
        "    for filename in tqdm(os.listdir(image_folder)):\n",
        "        img_path = os.path.join(image_folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        gray_img = np.zeros(img_rgb.shape[:2], dtype=np.uint8)\n",
        "\n",
        "        for rgb_color, gray_value in color_map.items():\n",
        "            mask = np.all(img_rgb == rgb_color, axis=-1)\n",
        "            gray_img[mask] = gray_value\n",
        "\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        cv2.imwrite(output_path, gray_img)\n",
        "\n",
        "    print(f\"Processing completed. Grayscale images saved in {output_folder}\")\n",
        "\n",
        "# Esempio di utilizzo\n",
        "image_folder = \"/content/drive/MyDrive/TACO dataset/defaultannot\"\n",
        "output_folder = \"/content/drive/MyDrive/TACO dataset/masks_new_categories\"\n",
        "\n",
        "replace_colors_with_grayscale(image_folder, fine_tune_dict, output_folder)\n"
      ],
      "metadata": {
        "id": "HJ5WqCHGhbFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def replace_pixel_values(folder_path, old_value, new_value):\n",
        "    \"\"\"\n",
        "    Sostituisce tutti i pixel con valore old_value con new_value\n",
        "    in tutte le immagini grayscale di una cartella.\n",
        "\n",
        "    Le immagini originali vengono sovrascritte.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): path alla cartella contenente le immagini.\n",
        "        old_value (int): valore pixel da sostituire.\n",
        "        new_value (int): nuovo valore pixel.\n",
        "    \"\"\"\n",
        "    # Controlla che i valori siano validi per immagini 8-bit\n",
        "    if not (0 <= old_value <= 255 and 0 <= new_value <= 255):\n",
        "        raise ValueError(\"old_value e new_value devono essere tra 0 e 255\")\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Controlla estensioni comuni di immagini\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):\n",
        "            # Leggi l'immagine in grayscale\n",
        "            img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None:\n",
        "                continue  # Se non riesce a leggere, passa oltre\n",
        "\n",
        "            # Sostituisci i pixel con valore old_value\n",
        "            img[img == old_value] = new_value\n",
        "\n",
        "            # Sovrascrivi l'immagine\n",
        "            cv2.imwrite(file_path, img)\n",
        "\n",
        "    print(\"Sostituzione completata.\")\n",
        "\n",
        "replace_pixel_values(\n",
        "    folder_path=\"/content/drive/MyDrive/TACO dataset/bibu\",\n",
        "    old_value=2,   # valore da sostituire\n",
        "    new_value=6    # nuovo valore\n",
        ")"
      ],
      "metadata": {
        "id": "12X2z1n1u9PL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = \"/content/drive/MyDrive/TACO dataset/masks_new_categories/7e2e4c62f0712d78_jpg.rf.eb8e4d1c5ad572cb57a8d17d1aa25858.png\"\n",
        "mask_image = Image.open(x).convert('L')\n",
        "mask_image = mask_image.resize((256,256), Image.NEAREST)\n",
        "\n",
        "plt.imshow(mask_image)\n",
        "mask_array = np.array(mask_image)\n",
        "print(np.unique(mask_array))"
      ],
      "metadata": {
        "id": "Dw5iDuDaFzEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analisi dataset"
      ],
      "metadata": {
        "id": "pLI3XqCU7Skm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check coppie immagini-maschera spaiati"
      ],
      "metadata": {
        "id": "BYeQ05xKEgxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder_images = \"/content/drive/MyDrive/TACO dataset/images_new_categories\"\n",
        "folder_masks = \"/content/drive/MyDrive/TACO dataset/masks_new_categories\"\n",
        "\n",
        "images = {os.path.splitext(f)[0] for f in os.listdir(folder_images) }\n",
        "masks = {os.path.splitext(f)[0] for f in os.listdir(folder_masks) }\n",
        "\n",
        "images_senza_maschere = images - masks\n",
        "maschere_senza_immagini = masks - images\n",
        "\n",
        "print(\"Immagini senza maschere:\", images_senza_maschere)\n",
        "print(\"Maschere senza immagini:\", maschere_senza_immagini)\n"
      ],
      "metadata": {
        "id": "7wU2ufd4W8iD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42ecf707-8df4-48b7-873c-8e5b7d6a068b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Immagini senza maschere: set()\n",
            "Maschere senza immagini: set()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "conteggio immagini"
      ],
      "metadata": {
        "id": "AHvUBqwlEoFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def count_files_in_folder(folder_path):\n",
        "    return sum(1 for entry in os.scandir(folder_path) if entry.is_file())\n",
        "\n",
        "folder = \"/content/drive/MyDrive/TACO dataset/images_new_categories\"\n",
        "num_files = count_files_in_folder(folder)\n",
        "print(f\"Numero di file: {num_files}\")"
      ],
      "metadata": {
        "id": "qgeru-6omM0E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "280bfa4d-b2c3-40b1-b335-37c155ed050a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numero di file: 3180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Esempi"
      ],
      "metadata": {
        "id": "8avLJ2N5vDmG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esempi di coppie immagine-maschera"
      ],
      "metadata": {
        "id": "xnjXqjIcFAKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Percorsi\n",
        "img_folder = ''\n",
        "masks_folder = ''\n",
        "\n",
        "# Classi mappate (solo le principali con ID > 0)\n",
        "class_labels = {\n",
        "    0: 'Background',\n",
        "    1: 'PLASTICA E POLIMERI',\n",
        "    2: 'METALLI',\n",
        "    3: 'VETRO',\n",
        "    4: 'CARTA E CARTONE',\n",
        "    5: 'POLISTIROLO',\n",
        "    6: 'SIGARETTE',\n",
        "    7: 'NON CLASSIFICATI',\n",
        "}\n",
        "\n",
        "# Colori associati (matplotlib tab20)\n",
        "colors = plt.cm.get_cmap('tab20', 20)\n",
        "\n",
        "def show_image_and_mask(image_path, mask_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Colora la maschera\n",
        "    mask_rgb = np.zeros_like(img)\n",
        "    for class_id, label in class_labels.items():\n",
        "        mask_rgb[mask == class_id] = (np.array(colors(class_id))[:3] * 255).astype(np.uint8)\n",
        "\n",
        "    # Estrai classi presenti\n",
        "    present_ids = np.unique(mask)\n",
        "    present_classes = [class_labels[class_id] for class_id in present_ids if class_id in class_labels]\n",
        "\n",
        "    # Plot affiancato\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    axs[0].imshow(img)\n",
        "    axs[0].set_title(\"Immagine originale\")\n",
        "    axs[0].axis('off')\n",
        "\n",
        "    axs[1].imshow(mask_rgb)\n",
        "    axs[1].set_title(\"Maschera semantica\")\n",
        "    axs[1].axis('off')\n",
        "\n",
        "    # Legenda\n",
        "    patches = [plt.plot([],[], marker=\"s\", ls=\"\", mec=None,\n",
        "                        color=colors(i)[:3], label=label)[0]\n",
        "               for i, label in class_labels.items() if i in present_ids]\n",
        "    plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Stampa classi trovate\n",
        "    print(\"Classi presenti nella maschera:\")\n",
        "    for class_id in present_ids:\n",
        "        if class_id in class_labels:\n",
        "            print(f\"  {class_id}: {class_labels[class_id]}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# ðŸ” Visualizza N esempi a partire da un count arbitrario con filtro filename\n",
        "N = 1500               # Numero massimo di immagini da visualizzare\n",
        "start_count = 0        # Quante immagini saltare prima di iniziare a mostrare\n",
        "filename_prefix = \"unofficial\"   # *** MODIFICA QUESTA STRINGA *** - lascia vuota per mostrare tutte le immagini\n",
        "\n",
        "count = 0\n",
        "shown = 0\n",
        "for fname in sorted(os.listdir(img_folder)):\n",
        "    if not fname.endswith('.jpg'):\n",
        "        continue\n",
        "\n",
        "    # *** NUOVO FILTRO *** - controlla se il filename inizia con la stringa specificata\n",
        "    if filename_prefix and not fname.startswith(filename_prefix):\n",
        "        continue\n",
        "\n",
        "    name, _ = os.path.splitext(fname)\n",
        "    mask_path = os.path.join(masks_folder, f\"{name}.png\")\n",
        "    img_path = os.path.join(img_folder, fname)\n",
        "\n",
        "    if os.path.exists(mask_path):\n",
        "        if count >= start_count:\n",
        "            print(f\"Mostrando: {fname}, count {count}\")\n",
        "            show_image_and_mask(img_path, mask_path)\n",
        "            shown += 1\n",
        "            if shown >= N:\n",
        "                break\n",
        "        count += 1\n",
        "\n",
        "# Stampa statistiche finali\n",
        "if filename_prefix:\n",
        "    print(f\"\\nFiltro applicato: filename che iniziano con '{filename_prefix}'\")\n",
        "print(f\"Immagini mostrate: {shown}\")\n",
        "print(f\"Immagini totali processate: {count}\")"
      ],
      "metadata": {
        "id": "6B8yNyjAsEUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creazione split"
      ],
      "metadata": {
        "id": "Lgid7NhLGz30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def stratified_fixed_split(mask_folder, image_folder, dest_folder, train_size=1832, val_size=350, test_size=350):\n",
        "    \"\"\"\n",
        "    Esegue lo split del dataset con numero fisso di immagini per split,\n",
        "    mantenendo la distribuzione di classi piÃ¹ bilanciata possibile.\n",
        "\n",
        "    Args:\n",
        "        mask_folder (str): Percorso delle maschere.\n",
        "        image_folder (str): Percorso delle immagini.\n",
        "        dest_folder (str): Cartella di destinazione degli split.\n",
        "        train_size (int): Numero di immagini per il training set.\n",
        "        val_size (int): Numero di immagini per il validation set.\n",
        "        test_size (int): Numero di immagini per il test set.\n",
        "    \"\"\"\n",
        "    os.makedirs(dest_folder, exist_ok=True)\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        os.makedirs(os.path.join(dest_folder, split, 'images'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(dest_folder, split, 'masks'), exist_ok=True)\n",
        "\n",
        "    # Carica le maschere e assegna le classi\n",
        "    class_to_files = defaultdict(list)\n",
        "    all_files = sorted([f for f in os.listdir(mask_folder) if f.lower().endswith('.png')])\n",
        "\n",
        "    for fname in all_files:\n",
        "        mask_path = os.path.join(mask_folder, fname)\n",
        "        mask = np.array(Image.open(mask_path))\n",
        "        unique_classes = set(np.unique(mask))\n",
        "        unique_classes.discard(0)  # rimuovi sfondo\n",
        "        for cls in unique_classes:\n",
        "            class_to_files[cls].append(fname)\n",
        "\n",
        "    # Filtra duplicati tra le classi e mescola\n",
        "    unique_files = list(set(f for files in class_to_files.values() for f in files))\n",
        "    random.shuffle(unique_files)\n",
        "\n",
        "    # Split fissato\n",
        "    total_required = train_size + val_size + test_size\n",
        "    if total_required > len(unique_files):\n",
        "        raise ValueError(f\"Richiesti {total_required} file ma disponibili solo {len(unique_files)}.\")\n",
        "\n",
        "    selected_files = unique_files[:total_required]\n",
        "    train_files = selected_files[:train_size]\n",
        "    val_files = selected_files[train_size:train_size + val_size]\n",
        "    test_files = selected_files[train_size + val_size:]\n",
        "\n",
        "    # Funzione di copia\n",
        "    def copy_files(file_list, split_name):\n",
        "        for fname in file_list:\n",
        "            src_img = os.path.join(image_folder, fname.replace('.png', '.jpg'))\n",
        "            if not os.path.exists(src_img):\n",
        "                src_img = os.path.join(image_folder, fname.replace('.png', '.JPG'))  # supporta anche JPG\n",
        "            dst_img = os.path.join(dest_folder, split_name, 'images', os.path.basename(src_img))\n",
        "            shutil.copy2(src_img, dst_img)\n",
        "\n",
        "            src_mask = os.path.join(mask_folder, fname)\n",
        "            dst_mask = os.path.join(dest_folder, split_name, 'masks', fname)\n",
        "            shutil.copy2(src_mask, dst_mask)\n",
        "\n",
        "    # Copia i file\n",
        "    print(\"Copia file...\")\n",
        "    copy_files(train_files, 'train')\n",
        "    copy_files(val_files, 'val')\n",
        "    copy_files(test_files, 'test')\n",
        "\n",
        "    print(f\"Split completato:\")\n",
        "    print(f\"Train: {len(train_files)} immagini\")\n",
        "    print(f\"Val: {len(val_files)} immagini\")\n",
        "    print(f\"Test: {len(test_files)} immagini\")\n",
        "\n",
        "stratified_fixed_split(\n",
        "    mask_folder='/content/drive/MyDrive/TACO dataset/masks_new_categories',\n",
        "    image_folder='/content/drive/MyDrive/TACO dataset/images_new_categories',\n",
        "    dest_folder='/content/drive/MyDrive/TACO dataset/dataset_split',\n",
        "    train_size=2700,\n",
        "    val_size=480,\n",
        "    test_size=0\n",
        ")"
      ],
      "metadata": {
        "id": "yAviAdIdR-EY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f19cd1a-5273-4726-895e-67b16a083005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copia file...\n",
            "Split completato:\n",
            "Train: 2700 immagini\n",
            "Val: 480 immagini\n",
            "Test: 0 immagini\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conteggio occorrenze classi"
      ],
      "metadata": {
        "id": "JGTKkOX6u65y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def count_class_occurrences_in_masks(mask_folder):\n",
        "    \"\"\"\n",
        "    Conta quante volte ciascun valore di classe appare almeno una volta in ogni maschera.\n",
        "\n",
        "    Args:\n",
        "        mask_folder (str): Cartella contenente le maschere semantiche (.png)\n",
        "\n",
        "    Returns:\n",
        "        dict: classe -> numero di immagini in cui appare\n",
        "    \"\"\"\n",
        "    class_counts = defaultdict(int)\n",
        "\n",
        "    mask_files = [f for f in os.listdir(mask_folder) if f.lower().endswith(\".png\")]\n",
        "\n",
        "    for mask_file in mask_files:\n",
        "        mask_path = os.path.join(mask_folder, mask_file)\n",
        "        mask = np.array(Image.open(mask_path))\n",
        "\n",
        "        # Estrai i valori unici presenti nella maschera\n",
        "        unique_values = np.unique(mask)\n",
        "\n",
        "        for val in unique_values:\n",
        "            class_counts[int(val)] += 1\n",
        "\n",
        "    return dict(class_counts)"
      ],
      "metadata": {
        "id": "2JuQR3_CXUhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_dir = \"/content/drive/MyDrive/TACO dataset/masks_new_categories\"\n",
        "counts = count_class_occurrences_in_masks(mask_dir)\n",
        "\n",
        "# Stampa ordinata\n",
        "for class_id in sorted(counts):\n",
        "    print(f\"Classe {class_id}: presente in {counts[class_id]} maschere\")\n",
        "\n",
        "'''\n",
        "    0: 'Background',\n",
        "    1: 'PLASTICA E POLIMERI',\n",
        "    2: 'METALLI',\n",
        "    3: 'VETRO',\n",
        "    4: 'CARTA E CARTONE',\n",
        "    5: 'POLISTIROLO',\n",
        "    6: 'SIGARETTE',\n",
        "    7: 'NON CLASSIFICATI'\n",
        "'''"
      ],
      "metadata": {
        "id": "yOGdnn7gXX7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Classe 0: presente in 3181 maschere\n",
        "- Classe 1: presente in 1183 maschere\n",
        "- Classe 2: presente in 720 maschere\n",
        "- Classe 3: presente in 609 maschere\n",
        "- Classe 4: presente in 726 maschere\n",
        "- Classe 5: presente in 604 maschere\n",
        "- Classe 6: presente in 613 maschere\n",
        "- Classe 7: presente in 523 maschere"
      ],
      "metadata": {
        "id": "w9CZBHCsORS2"
      }
    }
  ]
}